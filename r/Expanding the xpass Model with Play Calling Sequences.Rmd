---
title: "Expanding the xpass Model with Play-Calling Sequences"
output: html_notebook
---

# Purpose

To expand the pre-existing model for Expected Dropback (`xPass`) to better
detect patterns in offensive play-calling by adding in additional features
at varying levels-of-detail (LODs):

-   the static context of the individual play: personnel, formation, etc.
-   the cumulative history up to this point in the game (and possibly
    season): pass-rush splits, success rates, etc.
-   the pre-snap, frame-by-frame coordinates of players from the tracking
    data

# Setup

## Libraries

```{r message=FALSE, warning=FALSE}
library(tidyverse)
```

## Data

### Raw Input

```{r message=FALSE, warning=FALSE}
# non-tracking data
games <- readr::read_csv('./input/games.csv')
players <- readr::read_csv('./input/players.csv')
plays <- readr::read_csv('./input/plays.csv')
player_play <- readr::read_csv('./input/player_play.csv')

# nflverse data
nflverse_joined <- readr::read_tsv("./input/nflverse_joined.tsv")
```

```{r}
# tracking data
# TBD
```

## Functions

```{r}
# extracts position numbers from nflverse personnel columns
extract_personnel_count <- function(string, pos_name, default_NA = 0L) {

   # regex pattern to match a digit preceding the string pos_name
   p <- paste0("\\d[ ]", pos_name)


   # extracts the digit as a numeric value
   res <-
      as.numeric(
         stringr::str_extract(
            string = stringr::str_extract(string = string, pattern = p),
            pattern = "\\d")
      )


   # replace NA (no matching pos_name) with default
   # ret <- ifelse(is.na(res), default_NA, res)
   ret <- tidyr::replace_na(res, default_NA)


   return(ret)

}
```

# Transform

Create features for cumulative counting of plays for each team within a
game:

```{r}
pbp_rolling_counts <- 
   nflverse_joined |> 
   # only keep plays found in the BDB `plays` dataset
   semi_join(plays, by = join_by(gameId, playId)) |> 
   # reduce further and only include passes or rushes (excludes spikes, kneels, ...)
   filter(pass == 1 | rush == 1) |> 
   # flag to indicate a successful pass or rush attempt
   mutate(pass_success = (pass == 1 & success == 1),
          rush_success = (rush == 1 & success == 1)) |> 
   select(week, 
          gameId, 
          playId, 
          posteam, 
          defteam, 
          play_type, 
          pass, 
          rush, 
          success, 
          xpass, 
          pass_success, 
          rush_success) |> 
   # grouping variables for "rolling" (cumulative) counts
   group_by(week, gameId, posteam) |> 
   # number of plays and successes at overall, pass, and rush LOD:
   # where pass + rush = overall for both
   mutate(play_count = seq_along(playId),
          pass_count = cumsum(pass),
          rush_count = cumsum(rush),
          success_count = cumsum(success),
          pass_success_count = cumsum(pass_success),
          rush_success_count = cumsum(rush_success)) |> 
   ungroup() |> 
   # "rate-based" features:
   # success rate (overall, pass, rush)
   # pass rate (pass_rt + rush_rt = 1)
   mutate(success_rt = success_count / play_count, 
          pass_rt = pass_count / play_count, 
          pass_success_rt = pass_success_count / pass_count,
          rush_rt = rush_count / play_count, 
          rush_success_rt = rush_success_count / rush_count) |> 
   arrange(week, gameId, playId)
```

```{r}
pbp_rolling_counts
```

Create play-level features regarding personnel and formation info

```{r}
pbp_position_counts <- 
   nflverse_joined |> 
   # only keep plays found in the BDB `plays` dataset
   semi_join(plays, by = join_by(gameId, playId)) |> 
   # reduce further and only include passes or rushes (excludes spikes, kneels, ...)
   filter(pass == 1 | rush == 1) |> 
   select(week,
          gameId, 
          playId, 
          posteam,
          defteam,
          qb_location, 
          n_offense_backfield, 
          n_defense_box, 
          personnelOff, 
          personnelDef) |> 
   mutate(n_RB = extract_personnel_count(personnelOff, "RB"),
          n_WR = extract_personnel_count(personnelOff, "WR"),
          n_TE = extract_personnel_count(personnelOff, "TE"),
          n_DL = extract_personnel_count(personnelDef, "DL"),
          n_LB = extract_personnel_count(personnelDef, "LB"),
          n_DB = extract_personnel_count(personnelDef, "DB"),
          n_OL = extract_personnel_count(personnelOff, "OL", default_NA = 5),
          n_QB = extract_personnel_count(personnelOff, "QB", default_NA = 1)) |> 
   mutate(n_offense = n_RB + n_WR + n_TE + n_OL + n_QB,
          n_defense = n_DL + n_LB + n_DB) |> 
   filter(n_offense == 11,
          n_defense == 11,
          n_QB == 1) |> 
   select(-n_QB, -n_offense, -n_defense) |> 
   arrange(week, gameId, playId)
```

# Model

# Attempt 1 - Basic Logistic Regression

Use `xpass` along with the new personnel count features and the **pre-play**
(a.k.a. lagged) rolling count features to create a new prediction for
`xpass`

```{r}
model_data_01 <- 
   pbp_rolling_counts |> 
   group_by(week, gameId, posteam, defteam) |> 
   mutate(across(.cols = c(play_count:rush_success_rt),
                 .fns = function(x) lag(x))) |> 
   ungroup() |> 
   mutate(label = ifelse(pass == 1, 1, 0)) |> 
   select(week, 
          gameId, 
          playId, 
          posteam, 
          defteam, 
          play_count,
          success_count,
          pass_success_rt, 
          rush_success_rt, 
          xpass, 
          label) |> 
   inner_join(pbp_position_counts, 
              by = join_by(week, gameId, playId, posteam, defteam)) |> 
   select(-personnelOff, -personnelDef, -qb_location) |> 
   # filter out unqualified plays: 
   #    -first plays of the game w/o lag values, and
   #    -erroneous / abnormal personnel counts
   filter(!is.na(pass_success_rt), !is.na(rush_success_rt)) |> 
   filter(n_DL %in% c(2,3,4,5)) |> 
   filter(n_offense_backfield %in% c(0,1,2,3)) |> 
   filter(as.numeric(n_defense_box) >= 3)
```

```{r}
model_data_01
```

Remove any vars that aren't explicitly used in predictions as well as the
first 10 plays of each game(\*)

\* look into this filter further / validate its logic

```{r}
model_data_01b <- 
   model_data_01 |> 
   filter(play_count >= 10) |> 
   mutate(label = as.integer(label)) |> 
   select(-week, -gameId, -playId, -posteam, -defteam) |> 
   relocate(label)
```

Create train and test splits

```{r}
# first create an id column to join back to if needed
model_data_01b$id <- 1:nrow(model_data_01b) 
```

```{r}
set.seed(904) 

train_data_01 <- model_data_01b |> sample_frac(0.8)

test_data_01 <- model_data_01b |> anti_join(train_data_01, by = join_by(id))
```

Create basic logistic model

```{r}
model_01 <- 
   glm(label ~ xpass + 
          n_offense_backfield + 
          n_defense_box + 
          n_RB + n_WR + n_TE + 
          n_DL + n_LB + n_DB + 
          n_OL + 
          play_count + success_count + 
          pass_success_rt + rush_success_rt,
       data = train_data_01,
       family = binomial(link = "logit"))
```

Model summary:

```{r}
summary(model_01)
```

Statistically significant features are base xpass prediction,
n_offense_backfield, n_defense_box, n_RB/WR/TE, and the cumulative success
rates of both passing and rushing plays. Interesting that none of the
defensive personnel counts were significant here.

Make predictions on the test dataset

```{r}
# Predict probabilities on the test set
test_predictions <- predict(model_01, 
                            newdata = test_data_01, 
                            type = "response")
```

Explore results

```{r}
# Convert probabilities to binary predictions
# adjust the threshold if needed
binary_predictions <- ifelse(test_predictions > 0.5, 1, 0)


# Confusion Matrix
conf_matrix <- table(Actual = test_data_01$label, 
                     Predicted = binary_predictions)

# Performance Metrics
accuracy <- mean(binary_predictions == test_data_01$label)

# ROC Curve and AUC
pred_glm <- ROCR::prediction(test_predictions, test_data_01$label)
perf_glm <- ROCR::performance(pred_glm, "tpr", "fpr")
```

```{r}
# Calculate AUC
auc_glm <- ROCR::performance(pred_glm, "auc")
print(paste("AUC:", auc_glm@y.values[[1]]))
```

Additional detail/breakdown of ROC

```{r}
performance_measures_01 <- list()

# Precision-Recall Curve
performance_measures_01$precision_recall <- ROCR::performance(pred_glm, "prec", "rec")

# plot(precision_recall, main = "Precision-Recall Curve")

# Various Performance Metrics at Different Thresholds
performance_measures_01$acc <- ROCR::performance(pred_glm, "acc")

# plot(acc, main = "Accuracy vs. Threshold")

# Sensitivity and Specificity
performance_measures_01$sens <- ROCR::performance(pred_glm, "sens")
performance_measures_01$spec <- ROCR::performance(pred_glm, "spec")

# plot(sens, col = "blue", main = "Sensitivity and Specificity")
# plot(spec, add = TRUE, col = "red")
```

## Attempt 2 - Refined Logistic Regression

Since our first model dismissed defensive personnel, we'll shift our focus
to enhancing the features related to offensive personnel and formation. For
this iteration, I would like to add:

-   receiver alignment (3x1, 2x2, 2x1, ...)
-   number of receivers
-   proportion of successful plays that were a pass:
    `n successful pass plays / n successful plays`
    -   differs from current feature `pass_success_rt` which is:
        `n successful pass plays / n total pass plays` ("Out of all of our
        team's pass attempts, how many were successful?")
    -   this would instead be capturing the maths behind a thought process:
        "Out of all of our team's successful playcalls this game, how many
        were a pass?"

Create new modeling dataset:

```{r}
model_data_02 <- 
   pbp_rolling_counts |> 
   group_by(week, gameId, posteam, defteam) |> 
   mutate(across(.cols = c(play_count:rush_success_rt),
                 .fns = function(x) lag(x))) |> 
   ungroup() |> 
   mutate(success_proportion_pass = pass_success_count / success_count,
          success_proportion_rush = rush_success_count / success_count) |> 
   mutate(label = ifelse(pass == 1, 1L, 0L)) |> 
   inner_join(pbp_position_counts, 
              by = join_by(week, gameId, playId, posteam, defteam)) |> 
   inner_join(plays |> select(gameId, playId, offenseFormation, receiverAlignment),
              by = join_by(gameId, playId)) |> 
   mutate(n_receivers = case_match(receiverAlignment,
                                   c("2x2", "3x1") ~ 4,
                                   c("2x1", "3x0") ~ 3,
                                   c("3x2", "4x1") ~ 5,
                                   c("1x1", "2x0") ~ 2,
                                   c("3x3", "4x2") ~ 6,
                                   "1x0" ~ 1)) |> 
   mutate(across(.cols = starts_with("n_"), .fns = function(x) as.integer(x))) |> 
   #select(-personnelOff, -personnelDef) |> 
   # filter out unqualified plays: 
   #    -first plays of the game w/o lag values, and
   #    -erroneous / abnormal personnel counts
   filter(!is.na(pass_success_rt), !is.na(rush_success_rt)) |> 
   filter(n_DL %in% c(2,3,4,5)) |> 
   filter(n_offense_backfield %in% c(0,1,2,3)) |> 
   filter(as.numeric(n_defense_box) >= 3) |> 
   select(week, gameId, playId, posteam, defteam, 
          play_count, success_count,
          pass_success_rt, rush_success_rt, 
          xpass, label,
          n_offense_backfield, n_defense_box, 
          n_RB, n_WR, n_TE,
          success_proportion_pass, success_proportion_rush,
          n_receivers, receiverAlignment)
```

```{r}
model_data_02b <- 
   model_data_02 |> 
   arrange(week, gameId, playId) |> 
   filter(play_count >= 10) |> 
   filter(!is.na(success_proportion_pass),
          !is.na(success_proportion_rush),
          !is.na(n_receivers)) |> 
   select(-week, -gameId, -playId, -posteam, -defteam, -play_count, -success_count) |> 
   relocate(label) %>%
   mutate(id = c(1:nrow(.)))
```

```{r}
model_data_02b
```

Trains and test splits:

```{r}
set.seed(904) 

train_data_02 <- model_data_02b |> sample_frac(0.8)

test_data_02 <- model_data_02b |> anti_join(train_data_02, by = join_by(id))
```

Create model

```{r}
model_02 <- 
   glm(label ~ xpass + 
          n_offense_backfield + 
          n_defense_box + 
          n_RB + n_WR + n_TE + 
          pass_success_rt + rush_success_rt +
          success_proportion_pass + success_proportion_rush + 
          n_receivers,
       data = train_data_02,
       family = binomial(link = "logit"))
```

Model summary:

```{r}
summary(model_02)
```

Make predictions on the test dataset

```{r}
# Predict probabilities on the test set
test_predictions_02 <- predict(model_02,
                               newdata = test_data_02,
                               type = "response")
```

Explore results

```{r}
# Convert probabilities to binary predictions
# adjust the threshold if needed
binary_predictions_02 <- ifelse(test_predictions_02 > 0.5, 1, 0)


# Confusion Matrix
conf_matrix_02 <- table(Actual = test_data_02$label, 
                        Predicted = binary_predictions_02)

# Performance Metrics
accuracy_02 <- mean(binary_predictions_02 == test_data_02$label)

# ROC Curve and AUC
pred_glm_02 <- ROCR::prediction(test_predictions_02, test_data_02$label)
perf_glm_02 <- ROCR::performance(pred_glm_02, "tpr", "fpr")
auc_glm_02 <- ROCR::performance(pred_glm_02, "auc")
```

```{r}
# Print resulting accuracy and AUC values
print(paste0("Accuracy: ", 
             round(100*accuracy_02, digits = 1), 
             "%", 
             "  |  ", 
             "AUC: ", 
             round(auc_glm_02@y.values[[1]], digits = 3)))
```

Additional breakdown/metrics:

```{r}
performance_measures_02 <- list()

# Precision-Recall Curve
performance_measures_02$precision_recall <- ROCR::performance(pred_glm_02, "prec", "rec")

# Various Performance Metrics at Different Thresholds
performance_measures_02$acc <- ROCR::performance(pred_glm_02, "acc")

# Sensitivity and Specificity
performance_measures_02$sens <- ROCR::performance(pred_glm_02, "sens")
performance_measures_02$spec <- ROCR::performance(pred_glm_02, "spec")

# plots:
# plot(performance_measures_02$precision_recall, main = "Precision-Recall Curve")

# plot(performance_measures_02$acc, main = "Accuracy vs. Threshold")

# plot(performance_measures_02$sens, col = "blue", main = "Sensitivity and Specificity")
# plot(performance_measures_02$spec, add = TRUE, col = "red")
```

In short, Model 2 resulted in both added features (number of receivers and
success proportions) showing statistical significance, and an overall
improvement to accuracy and AUC compared to previous model.

# Future Work

Expand the `xpass` model further by adding in features from tracking data.
