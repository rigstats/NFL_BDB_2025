---
title: "Expanding the xpass Model"
output: html_notebook
---

# Purpose

Use tracking data, specifically with offensive linemen, to detect patterns
in offensive play-calling i.e. run/pass splits.

# Setup

## Libraries

```{r message=FALSE, warning=FALSE}
library(tidyverse)
```

## Data

```{r message=FALSE, warning=FALSE}
# non-tracking data
games <- readr::read_csv('./input/games.csv')
players <- readr::read_csv('./input/players.csv')
plays <- readr::read_csv('./input/plays.csv')
player_play <- readr::read_csv('./input/player_play.csv')

# nflverse data
nflverse_joined <- readr::read_tsv("./input/nflverse_joined.tsv")
```

```{r}
# additional nflverse data containing xpass variables
nflverse_gameInfo <- 
   nflreadr::load_schedules(seasons = 2022) |> 
   filter(week <= 9) |> 
   tibble() |> 
   select(week, 
          gameId = old_game_id,
          away_team, 
          home_team,
          away_moneyline,
          home_moneyline,
          roof) |> 
   mutate(
      across(
         .cols = c(away_moneyline, home_moneyline),
         .fns = function(x) ifelse(x > 0, 
                                   100 / (x + 100),
                                   abs(x) / (abs(x) + 100))
         ),
      gameId = as.integer(gameId),
      roof = as.factor(roof)
      ) |> 
   mutate(moneyline_vig = away_moneyline + home_moneyline - 1) |> 
   mutate(
      across(
         .cols = c(away_moneyline, home_moneyline),
         .fns = function(x) x - (moneyline_vig / 2)
      )
   ) |> 
   mutate(favoredTeam = 
             case_when(
                home_moneyline > away_moneyline ~ home_team,
                home_moneyline < away_moneyline ~ away_team,
                TRUE ~ NA_character_))
```

```{r}
# tracking data
tracking <- readRDS("./input/tracking_union_mod.rds")
```

## Functions

```{r}
# extracts position numbers from nflverse personnel columns
extract_personnel_count <- function(string, pos_name, default_NA=0L) {

   # regex pattern to match a digit preceding the string pos_name
   p <- paste0("\\d[ ]", pos_name)


   # extracts the digit as a numeric value
   res <-
      as.numeric(
         stringr::str_extract(
            string = stringr::str_extract(string = string, pattern = p),
            pattern = "\\d")
      )


   # replace NA (no matching pos_name) with default
   # ret <- ifelse(is.na(res), default_NA, res)
   ret <- tidyr::replace_na(res, default_NA)


   return(ret)

}
```

# Model

Original features of `xpass` below:

-   Yard line
-   Whether possession team is at home
-   Roof type (retractable, dome, or outdoors)
-   Down
-   Quarter
-   Half seconds remaining
-   Yards to go
-   Score differential
-   Timeouts remaining for each team
-   Win probability (both with spread and non-spread adjusted)

## Attempt 1: Expanded Play-Level Features

Make a version of `xpass` using additional features that are only at the
level-of-detail of the overall play. Including, but not limited to:

-   personnel of both offense and defense
-   offensive formation
-   receiver alignment
-   number of offensive players in backfield
-   number of defensive players in the box

```{r}
model_data_a <- 
   plays |> 
   select(gameId, 
          playId, 
          offenseFormation, 
          receiverAlignment, 
          label = isDropback) |> 
   inner_join(nflverse_joined |> 
                 filter(!is.na(xpass)) |> 
                 select(week, 
                        gameId, 
                        playId, 
                        xpass, 
                        qb_location, 
                        n_offense_backfield, 
                        n_defense_box, 
                        personnelOff, 
                        personnelDef),
              by = join_by(gameId, playId)) |> 
   mutate(n_RB = extract_personnel_count(personnelOff, "RB"),
          n_WR = extract_personnel_count(personnelOff, "WR"),
          n_TE = extract_personnel_count(personnelOff, "TE"),
          n_DL = extract_personnel_count(personnelDef, "DL"),
          n_LB = extract_personnel_count(personnelDef, "LB"),
          n_DB = extract_personnel_count(personnelDef, "DB"),
          n_OL = extract_personnel_count(personnelOff, "OL", default_NA = 5)) |> 
   arrange(week,
           gameId, 
           playId)
```

```{r}
model_data_a
```

Add a feature for number of players lined up as receivers from the receiver
alignment column.

```{r}
model_data_a$n_receivers <- 
   case_match(model_data_a$receiverAlignment,
              c("2x2", "3x1") ~ 4,
              c("2x1", "3x0") ~ 3,
              c("3x2", "4x1") ~ 5,
              c("1x1", "2x0") ~ 2,
              c("3x3", "4x2") ~ 6,
              "1x0" ~ 1
              )
```

Clean dataset by filtering erroneous data and rearranging (or removing)
columns

```{r}
model_data_b <- 
   model_data_a |> 
   filter(!is.na(offenseFormation),
          !is.na(qb_location),
          n_offense_backfield <= 3,
          n_defense_box >= 3) |> 
   mutate(label = as.integer(label)) |> 
   mutate(across(.cols = c(offenseFormation, receiverAlignment, qb_location),
                 .fns = function(x) as.integer(as.factor(x)))) |> 
   select(-personnelOff,
          -personnelDef) |> 
   relocate(week, gameId, playId, label, xpass)
```

Train and test splits

```{r}
test_data <- 
   model_data_b |> 
   filter(week >= 9)

train_data <- 
   model_data_b |> 
   filter(week < 9)

# explanation of this step below
folds <- 
   splitTools::create_folds(
      y = train_data$gameId,
      k = 5,
      type = "grouped",
      invert = TRUE
      )

train_labels <- train_data |> select(label)

# get rid of extra columns
train_data <- 
   train_data |> 
   select(-week, -gameId, -playId, -label)
```

Grid for hyperparameter tuning

```{r}
grid <- 
   dials::grid_space_filling(
  # this finalize thing is because mtry depends on # of columns in data
  dials::finalize(dials::mtry(), train_data),
  dials::min_n(),
  dials::tree_depth(),
  # to force learn_rate to not be crazy small like dials defaults to
  # because my computer is slow
  # if you're trying this for a different problem, expand the range here
  # by using more negative values
  dials::learn_rate(range = c(-1.5, -0.5), trans = scales::log10_trans()),
  dials::loss_reduction(),
  sample_size = dials::sample_prop(),
  size = 40
) %>%
  dplyr::mutate(
    # has to be between 0 and 1 for xgb
    # for some reason mtry gives the number of columns rather than proportion
    mtry = mtry / length(train_data)#,
    # see note below
    #monotone_constraints = "(1, 0, 0, 0, 1, 0, 1, -1, 0, 0, 0, 0, 1, -1)"

    # for the monotone constraints
    # these are notes to myself to make sure the constraints are in the right order
    # the order of the constraints needs to match up with the columns in the df

    # home, 0
    # down, 0
    # ydstogo, 1
    # x_LOS, 0
    # qtr, 0
    # wp, -1
    # score_differential, -1
    # half_seconds_remaining, 0
    # posteam_timeouts_remaining, 0
    # defteam_timeouts_remaining, 0
    # LT, -1
    # RT, -1
  ) %>%
  # make these the right names for xgb
  dplyr::rename(
    eta = learn_rate,
    gamma = loss_reduction,
    subsample = sample_size,
    colsample_bytree = mtry,
    max_depth = tree_depth,
    min_child_weight = min_n
  )
```

```{r}
grid
```

```{r}
# function to perform xgb.cv for a given row in a hyperparameter grid
get_row <- function(row) {
  params <-
    list(
      booster = "gbtree",
      objective = "binary:logistic",
      eval_metric = c("logloss"),
      eta = row$eta,
      gamma = row$gamma,
      subsample = row$subsample,
      colsample_bytree = row$colsample_bytree,
      max_depth = row$max_depth,
      min_child_weight = row$min_child_weight#,
#      monotone_constraints = row$monotone_constraints
    )

  # do the cross validation
  wp_cv_model <- xgboost::xgb.cv(
    data = as.matrix(train_data),
    label = train_labels$label,
    params = params,
    # this doesn't matter with early stopping in xgb.cv, just set a big number
    # the actual optimal rounds will be found in this tuning process
    nrounds = 15000,
    # created above
    folds = folds,
    metrics = list("logloss"),
    early_stopping_rounds = 50,
    print_every_n = 50
  )

  # bundle up the results together for returning
  output <- params
  output$iter <- wp_cv_model$best_iteration
  output$logloss <- wp_cv_model$evaluation_log[output$iter]$test_logloss_mean

  row_result <- bind_rows(output)

  return(row_result)
}
```

Run function on each row in our `grid`

```{r}
results <- 
   purrr::map_df(1:nrow(grid), function(x) get_row(grid |> slice(x)))
```

Plot results to see where to refine as needed

```{r}
results %>%
    dplyr::select(logloss, eta, gamma, subsample, 
                  colsample_bytree, max_depth, min_child_weight) %>%
    tidyr::pivot_longer(
        eta:min_child_weight,
        values_to = "value",
        names_to = "parameter"
    ) %>%
    ggplot(aes(value, logloss, color = parameter)) +
    geom_point(alpha = 0.8, show.legend = FALSE, size = 3) +
    facet_wrap(~parameter, scales = "free_x") +
    labs(x = NULL, y = "logloss") +
    theme_minimal()
```

From this, we should limit colsample_bytree to be less than 1/2, max_depth
less than or equal to 8, and learn rate no greater than 0.2(?)

We'll recreate an updated version of grid and rerun the results.

```{r}
grid_v2 <- 
   dials::grid_space_filling(
      # this finalize thing is because mtry depends on # of columns in data
      dials::mtry(range = c(length(train_data) / 2, length(train_data))),
      dials::min_n(),
      dials::tree_depth(),
      dials::learn_rate(range = c(-1.5, -0.5), 
                        trans = scales::log10_trans()),
      dials::loss_reduction(),
      sample_size = dials::sample_prop(),
      size = 40) |>
   dplyr::mutate(mtry = mtry / length(train_data)) |>
   # make these the right names for xgb
   dplyr::rename(
      eta = learn_rate,
      gamma = loss_reduction,
      subsample = sample_size,
      colsample_bytree = mtry,
      max_depth = tree_depth,
      min_child_weight = min_n)
```

```{r}
grid_v2
```

```{r}
results_v2 <- 
   purrr::map_df(1:nrow(grid_v2), 
                 function(x) get_row(grid |> slice(x)))
```

```{r}
# get the best results' parameters
best_model <- 
   results_v2 |> 
   arrange(logloss) |> 
   slice(1)

params <-
  list(
    booster = "gbtree",
    objective = "binary:logistic",
    eval_metric = c("logloss"),
    eta = best_model$eta,
    gamma = best_model$gamma,
    subsample = best_model$subsample,
    colsample_bytree = best_model$colsample_bytree,
    max_depth = best_model$max_depth,
    min_child_weight = best_model$min_child_weight#,
#    monotone_constraints = best_model$monotone_constraints
    )

nrounds <- best_model$iter
```

### Train the model

```{r}
xpass_model <- 
   xgboost::xgboost(
      params = params,
      data = as.matrix(train_data),
      label = train_labels$label,
      nrounds = nrounds,
      verbose = 2
)
```

### Predict on test data

```{r}
preds <- 
   stats::predict(
      xpass_model,
      # get rid of the things not needed for prediction here
      as.matrix(test_data |> select(-label, -gameId, -week, -playId))) |> 
   tibble::as_tibble() %>%
   dplyr::rename(xp = value) %>%
   dplyr::bind_cols(test_data)
```

### Evaluation

```{r}
MLmetrics::LogLoss(preds$xp, preds$label)
```

```{r}
MLmetrics::Accuracy(
  # say a team is predicted to win if they have pass prob > .5
  preds |> 
     dplyr::mutate(pred = ifelse(xp > .5, 1, 0)) |> 
     dplyr::pull(pred),
  # compare to whether they actually passed
  preds$label
)
```

## Basic Regression model?

```{r}
library(caret)
library(ROCR)
```

```{r}
# Split the data into training and testing sets
model_data_c <- 
   model_data_b |> 
   select(-offenseFormation,
          -receiverAlignment,
          -qb_location)
   

# set.seed(904)  # for reproducibility

train_data_glm <- model_data_c |> filter(week <= 8)

test_data_glm <- model_data_c |> filter(week == 9)
```

```{r}
logistic_model <- 
   glm(label ~ xpass + 
          n_offense_backfield + 
          n_defense_box + 
          n_RB + n_WR + n_TE + 
          n_DL + n_LB + n_DB + 
          n_OL + 
          n_receivers, 
       data = train_data_glm,
       family = binomial(link = "logit")
)
```

```{r}
# Predict probabilities on the test set
test_predictions <- predict(logistic_model, 
                            newdata = test_data_glm, 
                            type = "response")
```

```{r}
# Convert probabilities to binary predictions
# You can adjust the threshold if needed
binary_predictions <- ifelse(test_predictions > 0.5, 1, 0)


# Confusion Matrix
conf_matrix <- table(Actual = test_data_glm$label, 
                     Predicted = binary_predictions)

# Performance Metrics
accuracy <- mean(binary_predictions == test_data_glm$label)

# ROC Curve and AUC
pred_glm <- ROCR::prediction(test_predictions, test_data_glm$label)
perf_glm <- ROCR::performance(pred_glm, "tpr", "fpr")
```

```{r}
# Calculate AUC
auc_glm <- ROCR::performance(pred_glm, "auc")
print(paste("AUC:", auc_glm@y.values[[1]]))
```
